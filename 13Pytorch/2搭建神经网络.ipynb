{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 构建神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 搭建神经网络结构的组件在 torch.nn 中 ，这些神经网络层大多以类出现，例如全连接层：torch.nn.Linear() ，MSE 损失函数类torch.nn.MSELoss()  等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除此之外，torch.nn.functional  下面同样也有神经网络层，激活函数，损失函数等，但均以函数出现，例如全连接层函数：torch.nn.functional.linear() ，MSE 损失函数：torch.nn.functionalmse_loss()  等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 中每个样本是$28×28$的矩阵，目标是字符 0-9。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n",
      "'unzip' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "# 从蓝桥云课服务器下载数据集\n",
    "!wget -nc --restrict-file-names=nocontrol \"http://labfile.oss.aliyuncs.com/courses/1081/MNIST.zip\"\n",
    "!unzip -o \"MNIST.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "train = torchvision.datasets.MNIST(root='.',train=True,transform = torchvision.transforms.ToTensor(),\n",
    "                                   download=True)\n",
    "test = torchvision.datasets.MNIST(root='.',train = False,transform=torchvision.transforms.ToTensor(),\n",
    "                                  download=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的代码中，transform=torchvision.transforms.ToTensor()  是利用了 torchvision 提供的 transforms 直接将原 NumPy 数组转换为 PyTorch 张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]),\n",
       " torch.Size([60000]),\n",
       " torch.Size([10000, 28, 28]),\n",
       " torch.Size([10000]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data.shape, train.targets.shape, test.data.shape, test.targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们还需要使用 PyTorch 提供的一个组件对数据进行封装。torch.utils.data.DataLoader  是 PyTorch 提供的及其常用的数据加载器，它可以将数据集封装成迭代器以方便我们后续进行小批量加载，数据打乱等操作。数据加载器准备好之后，后续只需要通过 for 循环来使用即可。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x2bdd8dabe80>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x2bdd8dabf10>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train,batch_size=64,shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test,batch_size=64,shuffle=False)\n",
    "\n",
    "train_loader,test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，torch.nn 中的一个基础类 torch.nn.Module 。该类是 PyTorch 中所有神经网络的基类，它既可以表示神经网络中的某层，也可以表示若干层的神经网络。torch.nn 中的各个类实际上就是由 torch.nn.Modules 继承而拓展。所以，在实际使用中，我们可以继承nn.Module，撰写自定义网络层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以，当我们搭建神经网络时，也需要继承 torch.nn.Module。我们准备搭建一个包含两个隐含层的全连接网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入（784） → 全连接层 1 （784, 512）→ 全连接层 2 （512, 128）→ 输出（10）\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(784,512)\n",
    "        self.fc2 = nn.Linear(512,128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们定义了新的神经网络结构类 Net()，并使用 nn.Linear 组合了 3 个线性层（全连接层）。前向传播过程中，代码使用了 PyTorch 中常用的函数模块 torch.nn.functional 提供的 RELU 激活函数，实际上你也可以通过实例化 nn.Relu 来达到同样的效"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(),lr=0.002)\n",
    "# 值得注意的是，PyTorch 中优化器需传入模型的参数 model.parameters()，\n",
    "# 这是 PyTorch 的一个使用特性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "def fit(epochs,model,opt):\n",
    "    print(\"Start training, please be patient.\")\n",
    "    for epoch in range(epochs):\n",
    "        for i,(images,labels) in enumerate(train_loader):\n",
    "            images = images.reshape(-1,28*28)\n",
    "            labels = labels\n",
    "            output = model(images)\n",
    "            loss = loss_fn(output,labels)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step\n",
    "            if (i+1) % 100 == 0:\n",
    "                print('Epoch [{}/{}], Batch [{}/{}], Train loss: {:.3f}'\n",
    "                      .format(epoch+1, epochs, i+1, len(train_loader), \n",
    "loss.item()))\n",
    "                # 每个 Epoch 执行一次测试\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.reshape(-1, 28*28)\n",
    "            labels = labels\n",
    "            outputs = model(images)\n",
    "            # 得到输出最大值 _ 及其索引 predicted\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()  # 如果预测结果和真实值相等则计数 +1\n",
    "            total += labels.size(0)  # 总测试样本数据计数\n",
    "        print('============ Test accuracy: {:.3f} ============='.format(\n",
    "            correct / total))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training, please be patient.\n",
      "Epoch [1/1], Batch [100/938], Train loss: 2.294\n",
      "Epoch [1/1], Batch [200/938], Train loss: 2.304\n",
      "Epoch [1/1], Batch [300/938], Train loss: 2.294\n",
      "Epoch [1/1], Batch [400/938], Train loss: 2.320\n",
      "Epoch [1/1], Batch [500/938], Train loss: 2.304\n",
      "Epoch [1/1], Batch [600/938], Train loss: 2.311\n",
      "Epoch [1/1], Batch [700/938], Train loss: 2.300\n",
      "Epoch [1/1], Batch [800/938], Train loss: 2.306\n",
      "Epoch [1/1], Batch [900/938], Train loss: 2.290\n",
      "============ Test accuracy: 0.097 =============\n"
     ]
    }
   ],
   "source": [
    "fit(epochs=1, model=model, opt=opt)  # 训练 1 个 Epoch，预计持续 10 分钟"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，由于 PyTorch 没有提供类似于 Flatten 这样的展平类，所以我们通过 reshape 操作将输入 \n",
    "$28×28$ 展平为 784，使其和网络结构参数符合。你也可以使用 view，但官方更推荐使用 reshape 。\n",
    "\n",
    "其次，opt.zero_grad() 这步非常关键。由于 PyTorch 设计时梯度会累计，所以我们需要手动清零以实现传入一个 Batch，计算梯度，然后更新参数，从而不会因为前面的梯度累计影响后面的参数更新。但 PyTorch 这样设计也是有原因的，比如当我们想提升 Batch 的大小而硬件又无法处理较多数据时，就可以通过梯度累积机制，等待传入多个 Batch 后再更新参数并执行清零，这就给了开发更多的灵活性。同时，后续循环神经网络中也可能利用到这个特性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential 容器结构\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面，我们学习了使用 PyTorch 构建神经网络模型的经典方法步骤。你会发现 PyTorch 使用起来比 TensorFlow 要简单一些，主要体现在 DataLoader 数据加载器和前向传播过程调试较为方便，以及无需管理会话等。但是，PyTorch 又似乎比 Keras 要复杂一些，尤其是需要手动构建训练过程，还需要注意执行 opt.zero_grad() 等额外步骤。\n",
    "\n",
    "实际上，由于 PyTorch 未提供像 tf.keras 这种更高阶的 API，所以无法达到与 Keras 相似的便捷程度。不过，我们可以使用 PyTorch 提供的 Sequential 网络结构来优化上面的经典过程，使得神经网络结构定义的部分更精简一些。\n",
    "\n",
    "上面，我们通过继承 nn.Module 来定义了网络结构 Net() 类。实际上，利用 nn.Sequential  可以让这个过程更加直观简便。你可以直接按顺序将网络需要的组件类添加到 Sequential 容器结构中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_s = nn.Sequential(\n",
    "    nn.Linear(784,512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512,128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,10),)\n",
    "model_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们直接利用上面定义好的损失函数和训练函数完成模型优化迭代过程。由于优化器中需要传入模型的参数，所以这里需要修改为后续定义的 Sequential 模型。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training, please be patient.\n",
      "Epoch [1/1], Batch [100/938], Train loss: 2.316\n",
      "Epoch [1/1], Batch [200/938], Train loss: 2.302\n",
      "Epoch [1/1], Batch [300/938], Train loss: 2.311\n",
      "Epoch [1/1], Batch [400/938], Train loss: 2.303\n",
      "Epoch [1/1], Batch [500/938], Train loss: 2.295\n",
      "Epoch [1/1], Batch [600/938], Train loss: 2.298\n",
      "Epoch [1/1], Batch [700/938], Train loss: 2.316\n",
      "Epoch [1/1], Batch [800/938], Train loss: 2.305\n",
      "Epoch [1/1], Batch [900/938], Train loss: 2.309\n",
      "============ Test accuracy: 0.070 =============\n"
     ]
    }
   ],
   "source": [
    "opt_s = torch.optim.Adam(model_s.parameters(), lr=0.002)  # Adam 优化器\n",
    "fit(epochs=1, model=model_s, opt=opt_s)  # 训练 1 个 Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 GPU 加速训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后修改代码，数据和模型后面添加 .to(dev)，这样 PyTorch 就可以自动判断是否使用 GPU 加速了。首先是对从 DataLoader 中加载出来的每一批次数据后添加 .to(dev)。我们沿用 fit(epochs, model, opt) 中的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs,model,opt):\n",
    "    print(\"Start training, please be patient.\")\n",
    "    for epoch in range(epochs):\n",
    "        for i,(images,labels) in enumerate(train_loader):\n",
    "            images = images.reshape(-1,28*28).to(dev)\n",
    "            labels = labels.to(dev)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs,labels)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            if (i+1)%100==0:\n",
    "                print('Epoch[{}/{}],Batch[{}/{}],Train loss:{:.3f}'.format(epoch+1,epochs,i+1,len(train_loader),loss.item()))\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images,labels in test_loader:\n",
    "            images = images.reshape(-1,28*28).to(dev)\n",
    "            labels = labels.to(dev)\n",
    "            outputs = model(images)\n",
    "            _,predicted = torch.max(outputs.data,1)\n",
    "            correct +=(predicted==labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        print('============ Test accuracy: {:.3f} ============='.format(\n",
    "            correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training, please be patient.\n",
      "Epoch[1/1],Batch[100/938],Train loss:0.055\n",
      "Epoch[1/1],Batch[200/938],Train loss:0.094\n",
      "Epoch[1/1],Batch[300/938],Train loss:0.206\n",
      "Epoch[1/1],Batch[400/938],Train loss:0.040\n",
      "Epoch[1/1],Batch[500/938],Train loss:0.049\n",
      "Epoch[1/1],Batch[600/938],Train loss:0.106\n",
      "Epoch[1/1],Batch[700/938],Train loss:0.056\n",
      "Epoch[1/1],Batch[800/938],Train loss:0.056\n",
      "Epoch[1/1],Batch[900/938],Train loss:0.133\n",
      "============ Test accuracy: 0.968 =============\n"
     ]
    }
   ],
   "source": [
    "model_s.to(dev)\n",
    "opt_s = torch.optim.Adam(model_s.parameters(), lr=0.002)\n",
    "fit(epochs=1, model=model_s, opt=opt_s)  # 训练 1 个 Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型保存与推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_s, './model_s.pt') # .pt文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_s = torch.load('./model_s.pt')\n",
    "model_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_s = torch.load('./model_s.pt')\n",
    "model_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7, device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对测试数据第一个样本进行推理，注意将张量类型转换为 FloatTensor\n",
    "result = model_s(test.data[0].reshape(-1, 28*28).type(torch.FloatTensor).to(dev))\n",
    "torch.argmax(result)  # 找到输出最大值索引即为预测标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.targets[0]  # 第一个测试数据真实标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lanqiao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
